import cv2
import RPi.GPIO as GPIO
import time
import math
from picamera2 import Picamera2
from ultralytics import YOLO

def get_keypoint_position(keypoint_num, axis='x'):
    """ 
    Keypoint reference:
        0: nose          5: left_shoulder  10: right_wrist    15: left_ankle
        1: left_eye      6: right_shoulder 11: left_hip       16: right_ankle
        2: right_eye     7: left_elbow     12: right_hip
        3: left_ear		 8: right_elbow    13: left_knee
        4: right_ear	 9: left_wrist     14: right_knee
    """
    if not 0 <= keypoint_num <= 16:
        raise ValueError("Keypoint number must be between 0 and 16")
    if axis.lower() not in ['x', 'y']:
        raise ValueError("Axis must be 'x' or 'y'")
    
    # Get the keypoint data
    keypoint = results[0].keypoints.xyn[0][keypoint_num]
    
    # Return x or y coordinate based on axis parameter
    return keypoint[0].item() if axis.lower() == 'x' else keypoint[1].item()

# Set up the camera with Picam
picam2 = Picamera2()
picam2.preview_configuration.main.size = (1280, 1280)
picam2.preview_configuration.main.format = "RGB888"
picam2.preview_configuration.align()
picam2.configure("preview")
picam2.start()

# Load our YOLO11 model
model = YOLO("yolo11n-pose.pt")

# Initialize previous positions
previous_nose_x, previous_nose_y = 0, 0
previous_LA_x, previous_LA_y = 0, 0
previous_RA_x, previous_RA_y = 0, 0

#initialize pin for stepper
Dir = 22
Step = 23
CW = 1 #upward motion
CCW = 0 #downward motion
SPR = 200
step_count= SPR*D
delay = 0.005/N #speed can be an output value from later loop
CW = 1 #upward motion
CCW = 0 #downward motion
GPIO.setmode(GPIO.BCM)
GPIO.setup(Dir, GPIO.OUT)
GPIO.setup(Step,GPIO.out)
GPIO.output(Dir, SD) # the SD is a variable to specify direction in later command 

for x in range (step_count):
    GPIO.output(Step, GPIO.HIGH)
    sleep(delay)
    GIOP.output(Step, GPIO.LOW)
    sleep(delay)

while True:
    # Capture a frame from the camera
    frame = picam2.capture_array()
    
    # Run YOLO model on the captured frame and store the results
    results = model.predict(frame, imgsz=320, verbose=False)

    try:
        # Get nose position (keypoint 0)
        nose_x = get_keypoint_position(0, 'x')
        nose_y = get_keypoint_position(0, 'y')
        if abs(nose_x - previous_nose_x) > 0.01 or abs(nose_y - previous_nose_y) > 0.01:  # Threshold check
            print(f"Nose moved from {previous_nose_x} to {nose_x}")
            print(f"Nose moved from {previous_nose_y} to {nose_y}")
            time.sleep(0.05)  # Wait for 0.05 seconds before updating
            previous_nose_x = nose_x  # Update the previous x value after delay
            previous_nose_y = nose_y  # Update the previous y value after delay
            if nose_y > previous_nose_y:
                SD=CW     #set spin direction upward
                print("head is moving upward")
            if nose_y < previous_nose_y:
                SD=CCW   #set spin direction downward 
                print("head is moving downward")
            if abs(nose_y - previous_nose_y) < 0.01    #if the y value did not move larger than the set parameter, stop 
                step_count=0 #stopping the motor from taking any step
                print("head is not moving")

        print(f"Position - nose_x: {nose_x:.3f}, nose_y: {nose_y:.3f}")
        # Get left arm position (keypoint 9)
        LA_x= get_keypoint_position(9,'x')
        LA_y=get_keypoint_position(9,'y')
        print(f"Position - LA_X: {LA_X:.3f}, LA_Y: {LA_y:.3f}")
        # Get left arm position (keypoint 10)
        RA_x= get_keypoint_position(10,'x')
        RA_y=get_keypoint_position(10,'y')
        print(f"position - RA_x: {RA_x: .3f}, RA_y:{RA_y: .3f}")
                    
    except (IndexError, AttributeError):
        print("No person detected in frame")


    # change speed by changing the delay, depending on the magnitude of change
    try: 
        if abs(nose_x - previous_nose_x) < 0.01
            D=0 # 0 rpm, no speed
            print("you are moving too slow")
        if abs(nose_x - previous_nose_x) >= 0.01 and abs(nose_x - previous_nose_x) < 0.02:   
            N=2 # 120 rpm
            D=20
            print("speed 1")
        if abs(nose_x - previous_nose_x) >= 0.02 and abs(nose_x - previous_nose_x) < 0.03:   
            N=4 # 260 rpm
            D=20
            print("speed 2")
        if abs(nose_x - previous_nose_x) >= 0.03 and abs(nose_x - previous_nose_x) < 0.04:   
            N=4 # 260 rpm
            D=20
            print("speed 3")
        elseif abs(nose_x - previous_nose_x) > 0.04:
            N=8 # 480 rpm
            D=20
            print("speed 3")     
    except (IndexError, AttributeError):
        D=0 # No person in detected set speed to zero
        print("No person detected in frame")
        print("return to A pose")
    
    

    # Output the visual detection data
    annotated_frame = results[0].plot()
    
    # Get inference time and calculate FPS
    inference_time = results[0].speed['inference']
    fps = 1000 / inference_time
    text = f'FPS: {fps:.1f}'
    
    # Define font and position
    font = cv2.FONT_HERSHEY_SIMPLEX
    text_size = cv2.getTextSize(text, font, 1, 2)[0]
    text_x = annotated_frame.shape[1] - text_size[0] - 10
    text_y = text_size[1] + 10
    
    # Draw the FPS text
    cv2.putText(annotated_frame, text, (text_x, text_y), 
                font, 1, (255, 255, 255), 2, cv2.LINE_AA)
    
    # Display the frame
    cv2.imshow("Camera", annotated_frame)
    
    # Exit if 'q' is pressed
    if cv2.waitKey(1) == ord("q"):
        break

# Clean up
cv2.destroyAllWindows()
